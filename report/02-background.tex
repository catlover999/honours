\chapter{Background \& Related Work\label{chap:background}}

\section{Differential Privacy}

\acrfull{dp} is a mathematical framework for protecting individual privacy in datasets while allowing statistical analysis and insights to be derived from the data \cite{Dwork2006calibrating,Dwork2014}. It involves adding controlled noise to individual records to preserve privacy without diminishing utility beyond desired bounds \cite{WhatisDifferentialPrivacy}. Striking the correct balance between privacy and utility is at the heart of \acrshort{dp} research \cite{Dwork2014}. \acrshort{dp} aids in regulatory compliance and is widely deployed, often using bespoke implementations, to anonymize telemetry data on iOS, Android, Windows, and Chrome \cite{Maranon,markdefalco_2020}. Active research is conducted by both academia and industry, with notable groups including Microsoft's AI Lab, Google Research, Harvard's Privacy Tools Project, and Apple's Machine Learning Research - Differential Privacy Team.

\subsection{Foundations and Key Concepts}

The seminal work by \citet{Dwork2006calibrating} introduced \acrshort{dp}, proposing a mechanism for privacy-preserving statistical database queries by adding calibrated noise to query outputs. This work showed that privacy could be preserved by adjusting the noise scale according to the sensitivity of the computed function, ensuring that the presence or absence of any individual in the dataset does not significantly affect the analysis outcome. Subsequent research explored \acrshort{dp} mechanics, focusing on mechanisms that add noise to query outputs based on sensitivity \cite{Dwork2006calibrating}. The Laplace mechanism was introduced for adding scaled noise to ensure individual data does not significantly affect query outputs. The Gaussian mechanism was proposed as an alternative, offering better privacy-accuracy trade-offs under certain conditions \cite{Dwork2014}.
Additional concepts, such as privacy budget \cite{McSherry2007} and composability of \acrshort{dp} \cite{Dwork2014}, were introduced to highlight the cumulative nature of privacy loss across multiple queries and the importance of managing the budget to maintain robust guarantees. The distinction between global and local \acrshort{dp} was also made, differentiating between privacy guarantees provided by a trusted curator versus those provided in a decentralized manner \cite{kasiviswanathan2010learn}.

\subsection{Challenges and Open Problems}
Despite its emergence as a strong standard for privacy-preserving data analysis, \acrshort{dp} still faces challenges in practical implementation and adoption. The primary issue is the trade-off between privacy and utility, as adding noise to protect privacy can degrade the accuracy and usefulness of analysis results \cite{Dwork2014}. Balancing these competing objectives requires careful tuning of privacy parameters. Composition of \acrshort{dp} guarantees across multiple queries or analyses is another challenge, as each query consumes a portion of the privacy budget, and cumulative privacy loss must be tracked and controlled \cite{mcsherry2007mechanism}. Choosing appropriate sensitivity and privacy budget parameters is also crucial, as these values directly impact the privacy-utility trade-off \cite{Dwork2006calibrating}. Furthermore, implementing \acrshort{dp} mechanisms can be non-trivial, requiring careful attention to numerical stability, randomness generation, and code correctness to ensure the implementation accurately reflects the theoretical guarantees \cite{Mironov2012}.

\section{Existing Implementations of Differential Privacy}
Several software implementations aim to make \acrshort{dp} more practical and accessible to data analysts and scientists. This section reviews some of the most notable implementations.

\subsection{Google's Differential Privacy Library}
Google's commitment to \acrshort{dp} has evolved significantly since its early RAPPOR project in 2014. In 2019, Google launched an open-source \acrshort{dp} library written in C++, allowing developers to implement \acrshort{dp} in their applications \cite{Guevara_2022,RAPPOR,wilson2019differentially}. The library provides tools and features to facilitate \acrshort{dp} implementation, including mechanisms, algorithms, statistical functions, testing frameworks, and modular components \cite{wilson2019differentially,wilson2020differentially,RAPPOR}. It supports various programming languages and has been utilized in Google products like Maps and BigQuery \cite{Google_BigQuery}.

\subsection{Apple's Differential Privacy}
Apple has been a pioneer in deploying \acrshort{dp} at scale, first announcing its use in 2016 for collecting user data to improve services \cite{tang2017privacy,AppleDifferentialPrivacy2017}. Apple's implementation relies on a local model, adding noise to data on the user's device before sending it to servers, ensuring Apple only learns aggregate statistics. The technology is built into the core of Apple's operating systems and is used for various purposes, with technical whitepapers detailing the implementation and privacy guarantees \cite{AppleDifferentialPrivacy2017}.

\subsection{Microsoft's Differential Privacy Implementation}
Microsoft has contributed to \acrshort{dp} through theoretical research and practical implementations. A notable contribution is the SmartNoise system, developed in collaboration with Harvard as part of the OpenDP initiative \cite{MicrosoftOpenDP,MicrosoftHarvardOpenDP}. SmartNoise enables researchers and data scientists to derive insights from datasets while preserving individual privacy by adding statistical noise and managing a privacy-loss budget \cite{MicrosoftDataResponsibly}. Microsoft has applied \acrshort{dp} to Windows telemetry data and LinkedIn advertiser queries \cite{MicrosoftDataResponsibly}. While not directly applicable to the Fluent Bit filter plugin, Microsoft's work demonstrates the feasibility of deploying \acrshort{dp} in production environments.


\subsection{OpenDP}
OpenDP is a community effort to build an open-source suite of tools for deploying differential privacy \cite{opendp2020, Vadhan2019OpenDPA}. It consists of several projects and libraries in multiple languages, including a Rust-based library developed by researchers from Harvard that implements many common \acrshort{dp} algorithms. As detailed later in this report, the initial plan was to provide the Laplacian and Gaussian distributions through this. However, due to technical issues, it was found that the \texttt{Rv} Rust crate met the project requirements better due partly to it's narrower scope. OpenDP provides a wide range of tools, notably including making deferentially private queries from large datasets.

\subsection{Other Notable Implementations}
The US Census Bureau has adopted \acrshort{dp} as the new standard for protecting individual privacy in its data releases, using the TopDown algorithm to add noise hierarchically \cite{Gong2022Harnessing}. IBM's Diffprivlib is an open-source Python library for experimenting with \acrshort{dp}, designed for ease of use and providing a simple API for applying \acrshort{dp} to data analysis tasks \cite{holohan2019diffprivlib}.

\section{Log and Metric Processors}
Log and metric processors are essential tools for collecting, processing, and forwarding log data and metrics from various sources to multiple destinations. These processors play a crucial role in managing and analyzing large volumes of data generated by modern applications and infrastructure. Some notable log and metric processors include:

\subsection{Fluentd}
Fluentd is an open-source data collector that unifies data collection and consumption for better use and understanding of data \cite{fluentd}. It is written in Ruby and provides a flexible plugin system for extending its functionality. Fluentd is widely used in cloud environments and is known for its reliability and scalability. Fluentd and Fluent Bit were developed by the same organization, with Fluent Bit serving as a rewrite that aims to increase performance and a lower memory footprint. Though in lieu of a memory footprint that makes it practical to run even on embedded Linux devices, Fluentd makes up for it by having an order of magnitude more plugins available due to its more mature nature.

\section{Fluent Bit}
Fluent Bit is an industry-standard open-source Log and Metric processor capable of taking in \glspl{event} from a large variety of sources, applying filters, buffering, and then sending the processed data to a variety of destinations.\cite{What-is-Fluent-Bit} Written in C, it's YAML-based configuration defines a graph structure for where events should be sourced, what to do with the event, and where the event should be eventually sent. For example, a hub device running Fluent Bit could take in logs from a connected IoT device via MQTT. It can then extract a metric contained in the string, create a histogram based on those stored values, buffer the values to a persistent disk, and then send the stored data to a remote server using your desired protocol.

\subsection{Existing Fluent Bit WASM plugins}
An example of a plugin that leverages Fluent Bit's WASM filter plugin support is \textit{flb\_filter\_iis}\cite{Ortega}, which processes W3C's IIS-formatted logs into JSON to be consumed by Fluent Bit. It is an example of what's possible with stateless Rust WASM plugins for Fluent Bit, as it opens the door for using many Rust-native libraries in a containarized and portable environment. 

\subsection{Fluent Bit architecture}
At its core, Fluent Bit operates on a pluggable architecture, supporting a variety of input sources, filters for data processing, and output destinations. This modular design allows users to tailor the data pipeline according to their specific needs.
\begin{enumerate}
    \item Input: Fluent Bit starts by collecting data from various sources. These sources can be logs from files, system metrics, or data over the network. The input plugins are responsible for fetching this data and bringing it into Fluent Bit's internal processing pipeline. Common input plugins include tail (for tailing logs from files), mem (for memory metrics), and CPU (for CPU metrics).
    \item Processing: Once data is collected, it can be processed and transformed using filters. This step is crucial for preparing the data for its final destination, allowing for actions such as adding or removing records, modifying content, or aggregating logs. Processing can involve multiple filters, and Fluent Bit offers a range of filter plugins like grep (for filtering logs based on patterns), modify (for changing log content), and throttle (for limiting data throughput). This is where we can use Fluent Bit's facility to modify record content through a WASM filter plugin is used.
    \item Buffering: Fluent Bit can buffer data to disk or memory before sending it to the output destination. Buffering is important as it helps in managing data flow, ensuring that data is not lost during transmission spikes or network issues. The buffering mechanism can be configured to adjust the memory and storage usage based on the environment's requirements.
    \item Output: Finally, the processed and optionally buffered data is sent to one or more destinations. Fluent Bit supports a wide range of output plugins, allowing data to be forwarded to databases, logging services, monitoring tools, or storage systems. Some popular output destinations include Elasticsearch, Kafka, HTTP endpoints, and cloud services like Amazon S3 and Google Cloud Storage.
\end{enumerate}
Fluent Bit's lightweight design, flexibility, and portability makes it a popular choice for log and metric collection in various environments. Its ability to scale and handle large volumes of data efficiently, combined with the ease of customization through plugins, has contributed to its widespread adoption in industry.
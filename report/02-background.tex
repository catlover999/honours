\chapter{Background \& Related Work\label{chap:background}}

\section{Differential Privacy}

\acrfull{dp} is a mathematical framework for protecting individual privacy in datasets while allowing statistical analysis and insights to be derived from the data \cite{Dwork2006calibrating,Dwork2014}. It involves adding controlled noise to individual records to preserve privacy without diminishing utility beyond desired bounds \cite{WhatisDifferentialPrivacy}. Striking the correct balance between privacy and utility is at the heart of \acrshort{dp} research \cite{Dwork2014}. \acrshort{dp} aids in regulatory compliance and is widely deployed, often using bespoke implementations, to anonymize telemetry data on iOS, Android, Windows, and Chrome \cite{Maranon,markdefalco_2020}. Active research is conducted by both academia and industry, with notable groups including Microsoft's AI Lab, Google Research, Harvard's Privacy Tools Project, and Apple's Machine Learning Research - Differential Privacy Team.

\subsection{Foundations and Key Concepts}

The seminal work by \citet{Dwork2006calibrating} introduced \acrshort{dp}, proposing a mechanism for privacy-preserving statistical database queries by adding calibrated noise to query outputs. This work showed that privacy could be preserved by adjusting the noise scale according to the sensitivity of the computed function, ensuring that the presence or absence of any individual in the dataset does not significantly affect the analysis outcome. Subsequent research explored \acrshort{dp} mechanics, focusing on mechanisms that add noise to query outputs based on sensitivity \cite{Dwork2006calibrating}. The Laplace mechanism was introduced for adding scaled noise to ensure individual data does not significantly affect query outputs. The Gaussian mechanism was proposed as an alternative, offering better privacy-accuracy trade-offs under certain conditions \cite{Dwork2014}.
Additional concepts, such as privacy budget \cite{McSherry2007} and composability of \acrshort{dp} \cite{Dwork2014}, were introduced to highlight the cumulative nature of privacy loss across multiple queries and the importance of managing the budget to maintain robust guarantees. The distinction between global and local \acrshort{dp} was also made, differentiating between privacy guarantees provided by a trusted curator versus those provided in a decentralized manner \cite{kasiviswanathan2010learn}.

\subsection{Challenges and Open Problems}
Despite its emergence as a strong standard for privacy-preserving data analysis, \acrshort{dp} still faces challenges in practical implementation and adoption. The primary issue is the trade-off between privacy and utility, as adding noise to protect privacy can degrade the accuracy and usefulness of analysis results \cite{Dwork2014}. Balancing these competing objectives requires careful tuning of privacy parameters. Composition of \acrshort{dp} guarantees across multiple queries or analyses is another challenge, as each query consumes a portion of the privacy budget, and cumulative privacy loss must be tracked and controlled \cite{mcsherry2007mechanism}. Choosing appropriate sensitivity and privacy budget parameters is also crucial, as these values directly impact the privacy-utility trade-off \cite{Dwork2006calibrating}. Furthermore, implementing \acrshort{dp} mechanisms can be non-trivial, requiring careful attention to numerical stability, randomness generation, and code correctness to ensure the implementation accurately reflects the theoretical guarantees \cite{Mironov2012}.

\section{Existing Implementations of Differential Privacy}
Several software implementations aim to make \acrshort{dp} more practical and accessible to data analysts and scientists. This section reviews some of the most notable implementations.

\subsection{Google's Differential Privacy Library}
Google's commitment to \acrshort{dp} has evolved significantly since its early RAPPOR project in 2014. In 2019, Google launched an open-source \acrshort{dp} library written in C++, allowing developers to implement \acrshort{dp} in their applications \cite{Guevara_2022,RAPPOR,wilson2019differentially}. The library provides tools and features to facilitate \acrshort{dp} implementation, including mechanisms, algorithms, statistical functions, testing frameworks, and modular components \cite{wilson2019differentially,wilson2020differentially,RAPPOR}. It supports various programming languages and has been utilized in Google products like Maps and BigQuery \cite{Google_BigQuery}.

\subsection{Apple's Differential Privacy}
Apple has been a pioneer in deploying \acrshort{dp} at scale, first announcing its use in 2016 for collecting user data to improve services \cite{tang2017privacy,AppleDifferentialPrivacy2017}. Apple's implementation relies on a local model, adding noise to data on the user's device before sending it to servers, ensuring Apple only learns aggregate statistics. The technology is built into the core of Apple's operating systems and is used for various purposes, with technical whitepapers detailing the implementation and privacy guarantees \cite{AppleDifferentialPrivacy2017}.

\subsection{Microsoft's Differential Privacy Implementation}
Microsoft has contributed to \acrshort{dp} through theoretical research and practical implementations. A notable contribution is the SmartNoise system, developed in collaboration with Harvard as part of the OpenDP initiative \cite{MicrosoftOpenDP,MicrosoftHarvardOpenDP}. SmartNoise enables researchers and data scientists to derive insights from datasets while preserving individual privacy by adding statistical noise and managing a privacy-loss budget \cite{MicrosoftDataResponsibly}. Microsoft has applied \acrshort{dp} to Windows telemetry data and LinkedIn advertiser queries \cite{MicrosoftDataResponsibly}. While not directly applicable to the Fluent Bit filter plugin, Microsoft's work demonstrates the feasibility of deploying \acrshort{dp} in production environments.


\subsection{OpenDP}
OpenDP is a community effort to build an open-source suite of tools for deploying differential privacy \cite{opendp2020, Vadhan2019OpenDPA}. It consists of several projects and libraries in multiple languages, including a Rust-based library developed by researchers from Harvard that implements many common \acrshort{dp} algorithms. This was the initially planned library to provide the distributions for the Filter plugin implementation. However due to technical issues, it was found significantly simpler to use the \texttt{Rv} Rust crate due to it's more focused nature. More details can be found in the relevant design and implementation sections.

\subsection{Other Notable Implementations}
The US Census Bureau has adopted \acrshort{dp} as the new standard for protecting individual privacy in its data releases, using the TopDown algorithm to add noise hierarchically \cite{Gong2022Harnessing}. IBM's Diffprivlib is an open-source Python library for experimenting with \acrshort{dp}, designed for ease of use and providing a simple API for applying \acrshort{dp} to data analysis tasks \cite{holohan2019diffprivlib}.


\section{Fluent Bit}
Fluent Bit is an industry-standard open source Log and Metric processor capable of taking in events from a large variety of sources, applying filters, buffering, and then sending the processed data to a variety of destinations.\cite{What-is-Fluent-Bit} Written in C, it's YAML-based configuration defines a graph structure for where events should be sourced, what to do with the event, and where the event should be eventually sent. For example: a hub device running Fluent Bit could take in logs from a connected IoT device via MQTT, it then can extract a metric contained in the string, create a histogram based on those stored values, buffer the values to a persistent disk, then send the stored data to a remote server over your desired protocol.
\subsection{Other WASM plugins}
An example of a plugin that leverages Fluent Bit's WASM filter plugin support is \textit{flb\_filter\_iis}\cite{Ortega}, which processes W3C's IIS-formatted logs into JSON to be consumed by Fluent Bit. It is an example of what's possible with stateless Rust WASM plugins for Fluent Bit, as it opens the door for using many Rust-native libraries in a containarized and portable environment. 
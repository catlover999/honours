\chapter{Evaluation\label{chap:evaluation}}
\section{Experimental Design}
To evaluate the Rust plugin, we utilized a sample dataset consisting of two CSV files: "EmployeeSalaries.csv" and "StudentsPerformance.csv". The "EmployeeSalaries.csv" file contains information about employee salaries, including attributes such as department, gender, base salary, and overtime pay. The "StudentsPerformance.csv" file contains data related to student performance, including attributes like gender, race/ethnicity, parental education, and test scores.
The experimental setup involved the following steps:
\begin{enumerate}
    \item The sample dataset files were split into smaller chunks to simulate a streaming data scenario. Each file was divided into subfiles containing 200 records each.
    \item The Rust plugin was configured with specific differential privacy settings for each attribute. For the \texttt{"Base\_Salary"} attribute in the "EmployeeSalaries.csv" file, Gaussian noise with an epsilon value of 1.0 and a sensitivity of 10 was applied. For the \texttt{"math\_score"} \texttt{"reading\_score"}, and \texttt{"writing\_score"} attributes in the \texttt{"StudentsPerformance.csv"} file, Laplace noise was used with different epsilon values and sensitivities.
    \item Fluent Bit, a lightweight data processor, was used to process the data streams. The Rust plugin was integrated into Fluent Bit as a filter, allowing for the application of differential privacy mechanisms to the data in real-time.
    \item The perturbed datasets were stored in separate output files, "EmployeeSalaries.perturbed.csv" and "StudentsPerformance.perturbed.csv", for further analysis.
\end{enumerate}

\section{Evaluation Metrics}
To assess the performance of the differential privacy mechanisms implemented in the filter plugin, we employ three commonly used evaluation metrics: Mean Absolute Error (MAE), Mean Squared Error (MSE), and Root Mean Squared Error (RMSE). Equations in this section were sourced from \cite{Hodson2022}
\subsection{Mean Absolute Error (MAE)}
The Mean Absolute Error (MAE) measures the average magnitude of the errors between the original and perturbed values, without considering their direction. It is calculated by taking the average of the absolute differences between the original and perturbed values \cite{Willmott2005}. The formula for MAE is given by:
\begin{equation}
MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|
\end{equation}
where $n$ is the number of samples, $y_i$ is the original value, and $\hat{y}_i$ is the perturbed value.
\subsection{Mean Squared Error (MSE)}
The Mean Squared Error (MSE) measures the average squared difference between the original and perturbed values \cite{ZhouWang2009}. It is calculated by taking the average of the squared differences between the original and perturbed values. The formula for MSE is given by:
\begin{equation}
MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
\end{equation}
MSE gives more weight to larger errors due to the squaring operation, making it more sensitive to outliers compared to MAE.
\subsection{Root Mean Squared Error (RMSE)}
The Root Mean Squared Error (RMSE) is the square root of the Mean Squared Error \cite{Chai2014}. It is calculated by taking the square root of the average squared differences between the original and perturbed values. The formula for RMSE is given by:
\begin{equation}
RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}
\end{equation}
RMSE has the same units as the original data, making it easier to interpret compared to MSE. It is also more sensitive to larger errors due to the squaring operation.
These evaluation metrics provide insights into the accuracy and utility of the differentially private data generated by the filter plugin. Lower values of MAE, MSE, and RMSE indicate better performance and higher data utility.

\subsection{Test Environment}
The test environment was constructed with a multi-build context Docker container. The first two stages concerned themselves with building the filter plugin along with Fluent Bit with a non-default build option (only needed if AoT is to be built).

\subsection{Experimental Setup}
The experimental setup involved running the Docker container, which executed the data processing pipeline. The split sample dataset files were ingested by Fluent Bit, processed by the Rust filter plugin with the specified differential privacy settings, and the perturbed outputs were saved to separate CSV files.

\section{Results}
After running the experiment, the original and perturbed datasets were analyzed using a Jupyter Notebook. The notebook calculated the MAE, MSE, and RMSE for each perturbed attribute and visualized the distributions of the original and perturbed values.
For the "Base\_Salary" attribute, which used Gaussian noise with $\varepsilon=1.0$ and sensitivity=10, the following results were obtained:

\begin{itemize}
    \item MAE: 7.90
    \item MSE: 99.20
    \item RMSE: 9.96
\end{itemize}

For the student performance attributes, which used Laplace noise with varying $\varepsilon$ and sensitivity values:
\begin{table}[h]
    \centering
    \begin{tabular}{l|c|c|c}
    \hline
    \textbf{Attribute} & \textbf{MAE} & \textbf{MSE} & \textbf{RMSE} \\
    \hline
    math\_score ($\varepsilon=1.0$, sensitivity=7.58) & 5.70 & 52.81 & 7.27 \\
    reading\_score ($\varepsilon=0.75$, sensitivity=7.3) & 7.60 & 93.64 & 9.68 \\
    writing\_score ($\varepsilon=0.5$, sensitivity=7.6) & 11.40 & 210.25 & 14.50 \\
    \hline
    \end{tabular}
    \caption{Evaluation results for student performance attributes}
    \label{tab:student_scores}
\end{table}

\section{Analysis}
The results demonstrate the impact of the differential privacy mechanisms on the data utility. The MAE, MSE, and RMSE values quantify the average magnitude and squared differences between the original and perturbed values.
For the "Base\_Salary" attribute, the Gaussian mechanism with $\varepsilon=1.0$ and sensitivity=10 resulted in an MAE of 7.90, indicating that on average, the perturbed values deviated from the original values by around \$7,900. The MSE of 99.20 and RMSE of 9.96 suggest that the squared errors were relatively high, with some perturbed values differing significantly from the original ones.
In the case of the student performance attributes, the Laplace mechanism was used with different $\varepsilon$ and sensitivity values for each attribute. The "math\_score" attribute, with $\varepsilon=1.0$ and sensitivity=7.58, had the lowest MAE (5.70), MSE (52.81), and RMSE (7.27) among the three attributes. This indicates that the perturbed "math\_score" values were closer to the original values compared to the other attributes.

The "reading\_score" attribute, with $\varepsilon=0.75$ and sensitivity=7.3, had slightly higher error metrics (MAE=7.60, MSE=93.64, RMSE=9.68) compared to "math\_score". The lower $\varepsilon$ value resulted in more noise being added to the data, leading to larger deviations from the original values.
The "writing\_score" attribute, with $\varepsilon=0.5$ and sensitivity=7.6, exhibited the highest error metrics (MAE=11.40, MSE=210.25, RMSE=14.50). The low $\varepsilon$ value of 0.5 resulted in a significant amount of noise being added to the data, causing substantial differences between the original and perturbed values.

\section{Interpretation of Results}
The evaluation results highlight the trade-off between privacy and utility when applying differential privacy mechanisms. Lower $\varepsilon$ values provide stronger privacy guarantees but lead to higher levels of noise and reduced data utility, as evidenced by the higher MAE, MSE, and RMSE values.
The choice of $\varepsilon$ and sensitivity values depends on the specific privacy requirements and the acceptable level of data utility for the given application. In scenarios where privacy is of utmost importance, lower $\varepsilon$ values may be necessary, even at the cost of reduced utility. On the other hand, if maintaining data utility is critical, higher $\varepsilon$ values can be chosen, but this comes with weaker privacy guarantees.

The results also demonstrate the effectiveness of the implemented Rust filter plugin in applying differential privacy mechanisms to streaming data using Fluent Bit. The plugin successfully perturbed the sensitive attributes based on the specified privacy settings, enabling privacy-preserving data analysis.

Overall, the evaluation highlights the importance of carefully selecting differential privacy parameters based on the desired balance between privacy and utility. The developed Rust filter plugin provides a flexible and efficient solution for integrating differential privacy into data processing pipelines using Fluent Bit.